{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBpG2dNIoQBaVks91oLbZI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Icaro1549/Perceptron-Simples-/blob/main/paracasa_aula4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Para casa da aula do dia 9/9\n",
        "\n",
        "codigo original"
      ],
      "metadata": {
        "id": "KQQd_8RQY-Bt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GgaP1gLtY6D6"
      },
      "outputs": [],
      "source": [
        "#import = icorporando uma biblioteca\n",
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "  #construtor da calsse\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train(self, inputs, outputs, learning_rate=0.1, epochs=100):\n",
        "    self.imputs = inputs\n",
        "    self.outputs = outputs\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "\n",
        "    #inicialização dos pessos iniciais de forma aleatoria\n",
        "    w1, w2, bias = np.random.uniform(-1, 1), np.random.uniform(-1, 1), np.random.uniform(-1, 1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "      for j in range(len(inputs)): #len te da o tamanho dos vetores/listas/matriz/entradas\n",
        "\n",
        "         # função de ativação sigmoid faz o lançamento de 0 e 1\n",
        "         sigmoid = 1/(1 + np.exp(-(w1 * inputs[j][0] + w2 * inputs[j][1] + bias)))\n",
        "         # atualização dos pesos por ITERAÇÃO\n",
        "         w1 = w1 + learning_rate * (outputs [j] [0] - sigmoid) * inputs[j][0]\n",
        "         w2 = w2 + learning_rate * (outputs [j] [0] - sigmoid) * inputs[j][1]\n",
        "         bias =  bias + (learning_rate * (outputs [j] [0] - sigmoid)) #essas 3 linhas tão reacalculando os pesos\n",
        "\n",
        "    return w1, w2, bias\n",
        "\n",
        "  def predict(self, weights, x1, x2):\n",
        "    #Podemos usar a função degral ou a função sogmoid, mas estamos usando função sigmoid nessa\n",
        "    return 1 if 1/(1 + np.exp(-((x1 * weights[0]) + (x2 * weights[1]) + weights[2]))) > 0.5 else 0\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  #entradas das portas logicas em pares\n",
        "  inputs = [[0,0], [0,1], [1,0], [1,1]]\n",
        "  outputs = [[0],   [1],   [1],   [1]]\n",
        "\n",
        "  perceptron = Perceptron()\n",
        "\n",
        "  #treinando o perceptron\n",
        "\n",
        "  tranning = perceptron.train(inputs,\n",
        "                             outputs,\n",
        "                             learning_rate=0.1,\n",
        "                             epochs=100)\n",
        "\n",
        "perdiction = perceptron.predict(tranning, 1, 0)\n",
        "\n",
        "print(perdiction)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1\n",
        "\n",
        "varie a taxa de aprendizado e verifique o impaccto no treinamento\n",
        "\n"
      ],
      "metadata": {
        "id": "aX6NbwEUZLDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train(self, inputs, outputs, learning_rate=1, epochs=100):\n",
        "    self.imputs = inputs\n",
        "    self.outputs = outputs\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "\n",
        "    w1, w2, bias = np.random.uniform(-1, 1), np.random.uniform(-1, 1), np.random.uniform(-1, 1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "      for j in range(len(inputs)):\n",
        "\n",
        "\n",
        "         sigmoid = 1/(1 + np.exp(-(w1 * inputs[j][0] + w2 * inputs[j][1] + bias)))\n",
        "         w1 = w1 + learning_rate * (outputs [j] [0] - sigmoid) * inputs[j][0]\n",
        "         w2 = w2 + learning_rate * (outputs [j] [0] - sigmoid) * inputs[j][1]\n",
        "         bias =  bias + (learning_rate * (outputs [j] [0] - sigmoid))\n",
        "\n",
        "    return w1, w2, bias\n",
        "\n",
        "  def predict(self, weights, x1, x2):\n",
        "    return 1 if 1/(1 + np.exp(-((x1 * weights[0]) + (x2 * weights[1]) + weights[2]))) > 0.5 else 0\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  inputs = [[0,0], [0,1], [1,0], [1,1]]\n",
        "  outputs = [[0],   [1],   [1],   [1]]\n",
        "\n",
        "  perceptron = Perceptron()\n",
        "\n",
        "  tranning = perceptron.train(inputs,\n",
        "                             outputs,\n",
        "                             learning_rate=-0.5,\n",
        "                             epochs=100)\n",
        "\n",
        "prediction = perceptron.predict(tranning, 1, 0)\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# variando a taxa entre valores positivos e negativos eu chegeuia conclusão de que, valores positivos tendem a dar o valor 1 em quanto valores negativos tendem a retornar 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wnzJ05VZazE",
        "outputId": "8c5c59e4-ff69-4ad7-e8bd-45f2a1fd0367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2\n",
        "\n",
        "varie a quantidade de epocas"
      ],
      "metadata": {
        "id": "9sc0OW1wgbd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train(self, inputs, outputs, learning_rate=1, epochs=100):\n",
        "    self.imputs = inputs\n",
        "    self.outputs = outputs\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "\n",
        "    w1, w2, bias = np.random.uniform(-1, 1), np.random.uniform(-1, 1), np.random.uniform(-1, 1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "      for j in range(len(inputs)):\n",
        "\n",
        "\n",
        "         sigmoid = 1/(1 + np.exp(-(w1 * inputs[j][0] + w2 * inputs[j][1] + bias)))\n",
        "         w1 = w1 + learning_rate * (outputs [j] [0] - sigmoid) * inputs[j][0]\n",
        "         w2 = w2 + learning_rate * (outputs [j] [0] - sigmoid) * inputs[j][1]\n",
        "         bias =  bias + (learning_rate * (outputs [j] [0] - sigmoid))\n",
        "\n",
        "    return w1, w2, bias\n",
        "\n",
        "  def predict(self, weights, x1, x2):\n",
        "    return 1 if 1/(1 + np.exp(-((x1 * weights[0]) + (x2 * weights[1]) + weights[2]))) > 0.5 else 0\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  inputs = [[0,0], [0,1], [1,0], [1,1]]\n",
        "  outputs = [[0],   [1],   [1],   [1]]\n",
        "\n",
        "  perceptron = Perceptron()\n",
        "\n",
        "  tranning = perceptron.train(inputs,\n",
        "                             outputs,\n",
        "                             learning_rate=-0.5,\n",
        "                             epochs=2)\n",
        "\n",
        "prediction = perceptron.predict(tranning, 1, 0)\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "\n",
        "# não impotvava quanto eu alterasse os valores das epocas, os resultados continuavam os mesmos, mas quando maior o numeros de epocas mais demoarva pro codigo rodar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCnyEj_jgnSK",
        "outputId": "a170191b-05e3-41ae-f3ac-e0e5a4b13a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3\n",
        "\n",
        "testando com porta AND"
      ],
      "metadata": {
        "id": "x7OaeZWxhkzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  def train(self, inputs, outputs, learning_rate=1, epochs=100):\n",
        "    self.imputs = inputs\n",
        "    self.outputs = outputs\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "\n",
        "    w1, w2, bias = np.random.uniform(-1, 1), np.random.uniform(-1, 1), np.random.uniform(-1, 1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "      for j in range(len(inputs)):\n",
        "\n",
        "\n",
        "         sigmoid = 1/(1 + np.exp(-(w1 * inputs[j][0] + w2 * inputs[j][1] + bias)))\n",
        "         w1 = w1 + learning_rate * (outputs [j] [0] - sigmoid) * inputs[j][0]\n",
        "         w2 = w2 + learning_rate * (outputs [j] [0] - sigmoid) * inputs[j][1]\n",
        "         bias =  bias + (learning_rate * (outputs [j] [0] - sigmoid))\n",
        "\n",
        "    return w1, w2, bias\n",
        "\n",
        "  def predict(self, weights, x1, x2):\n",
        "    return 1 if 1/(1 + np.exp(-((x1 * weights[0]) + (x2 * weights[1]) + weights[2]))) > 0.5 else 0\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  inputs = [[0,0], [0,1], [1,0], [1,1]]\n",
        "  outputs = [[0],   [0],   [0],   [1]]\n",
        "\n",
        "  perceptron = Perceptron()\n",
        "\n",
        "  tranning = perceptron.train(inputs,\n",
        "                             outputs,\n",
        "                             learning_rate=-0.5,\n",
        "                             epochs=100)\n",
        "\n",
        "prediction = perceptron.predict(tranning, 1, 0)\n",
        "\n",
        "print(prediction)\n",
        "\n",
        "\n",
        "# a unica diferença que eu consegui reparar entre os dois as duas saidas, AND e OR, é que: o que antes dava 0 agora esta dando 1 e o que dava 1 esta dando 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS9upE7_h15m",
        "outputId": "f8e00ca2-94ca-421a-ffa4-63a4301dc119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5\n",
        "\n",
        "extrair a função de ativação"
      ],
      "metadata": {
        "id": "Ut5DQbkgkKE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "  def _init_(self):\n",
        "    pass\n",
        "\n",
        "  def activation_function(self, x): #Função de ativação Sigmóide\n",
        "      return 1 / (1 + np.exp(-x))\n",
        "\n",
        "  def train(self, inputs, outputs, learning_rate=10, epochs=100):\n",
        "    self.inputs = inputs\n",
        "    self.outputs = outputs\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "\n",
        "    w1, w2, bias = np.random.uniform(-1, 1), np.random.uniform(-1, 1), np.random.uniform(-1, 1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "      for j in range(len(inputs)):\n",
        "         # usa a função de ativação separada\n",
        "         z = w1 * inputs[j][0] + w2 * inputs[j][1] + bias\n",
        "         sigmoid = self.activation_function(z)\n",
        "\n",
        "         w1 = w1 + learning_rate * (outputs[j][0] - sigmoid) * inputs[j][0]\n",
        "         w2 = w2 + learning_rate * (outputs[j][0] - sigmoid) * inputs[j][1]\n",
        "         bias = bias + learning_rate * (outputs[j][0] - sigmoid)\n",
        "\n",
        "    return w1, w2, bias\n",
        "\n",
        "  def predict(self, weights, x1, x2):\n",
        "    z = (x1 * weights[0]) + (x2 * weights[1]) + weights[2]\n",
        "    return 1 if self.activation_function(z) > 0.5 else 0\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  inputs = [[0,0], [0,1], [1,0], [1,1]]\n",
        "  outputs = [[0],   [1],   [1],   [1]]\n",
        "\n",
        "  perceptron = Perceptron()\n",
        "\n",
        "  tranning = perceptron.train(inputs,\n",
        "                             outputs,\n",
        "                             learning_rate=10,\n",
        "                             epochs=100)\n",
        "\n",
        "  prediction = perceptron.predict(tranning, 1, 0)\n",
        "  print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUd8d4LnqJGc",
        "outputId": "677a3fce-9d81-4c01-a2d4-20f360d6b2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4\n",
        "\n",
        "Transofrme a função de ativação para funcão degral"
      ],
      "metadata": {
        "id": "Xzy0STeprGwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "  def _init_(self):\n",
        "    pass\n",
        "\n",
        "  def activation_function(self, x):\n",
        "      return 1 if x >= 0 else 0\n",
        "\n",
        "  def train(self, inputs, outputs, learning_rate=10, epochs=100):\n",
        "    self.inputs = inputs\n",
        "    self.outputs = outputs\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "\n",
        "    w1, w2, bias = np.random.uniform(-1, 1), np.random.uniform(-1, 1), np.random.uniform(-1, 1)\n",
        "\n",
        "    for i in range(epochs):\n",
        "      for j in range(len(inputs)):\n",
        "         # usa a função de ativação separada\n",
        "         z = w1 * inputs[j][0] + w2 * inputs[j][1] + bias\n",
        "         sigmoid = self.activation_function(z)\n",
        "\n",
        "         w1 = w1 + learning_rate * (outputs[j][0] - sigmoid) * inputs[j][0]\n",
        "         w2 = w2 + learning_rate * (outputs[j][0] - sigmoid) * inputs[j][1]\n",
        "         bias = bias + learning_rate * (outputs[j][0] - sigmoid)\n",
        "\n",
        "    return w1, w2, bias\n",
        "\n",
        "  def predict(self, weights, x1, x2):\n",
        "    z = (x1 * weights[0]) + (x2 * weights[1]) + weights[2]\n",
        "    return 1 if self.activation_function(z) > 0.5 else 0\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  inputs = [[0,0], [0,1], [1,0], [1,1]]\n",
        "  outputs = [[0],   [1],   [1],   [1]]\n",
        "\n",
        "  perceptron = Perceptron()\n",
        "\n",
        "  tranning = perceptron.train(inputs,\n",
        "                             outputs,\n",
        "                             learning_rate=10,\n",
        "                             epochs=100)\n",
        "\n",
        "  prediction = perceptron.predict(tranning, 1, 0)\n",
        "  print(prediction)\n",
        "\n",
        "# Eu não consigo reapar em nehuma diferença no impacto de qualidade entra a função sigmoid e a função degrau"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T95ck8QrZ4J",
        "outputId": "e2428e5c-4865-4545-9b34-6eb9ee63eff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    }
  ]
}